{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T13:49:11.396496Z",
     "iopub.status.busy": "2024-06-11T13:49:11.395893Z",
     "iopub.status.idle": "2024-06-11T13:49:11.669065Z",
     "shell.execute_reply": "2024-06-11T13:49:11.668498Z",
     "shell.execute_reply.started": "2024-06-11T13:49:11.396474Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T13:49:11.670610Z",
     "iopub.status.busy": "2024-06-11T13:49:11.670100Z",
     "iopub.status.idle": "2024-06-11T13:49:11.673550Z",
     "shell.execute_reply": "2024-06-11T13:49:11.673033Z",
     "shell.execute_reply.started": "2024-06-11T13:49:11.670590Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "siteid_dict = {\n",
    "    '555 Taxter':'US-NY-010523-1901',\n",
    "    '565 Taxter':'US-NY-010523-1900',\n",
    "    '4WRO':'US-NY-010604-2000',\n",
    "    '660 WP':'US-NY-010591-1900'\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T13:49:11.674879Z",
     "iopub.status.busy": "2024-06-11T13:49:11.674398Z",
     "iopub.status.idle": "2024-06-11T13:49:11.681324Z",
     "shell.execute_reply": "2024-06-11T13:49:11.680795Z",
     "shell.execute_reply.started": "2024-06-11T13:49:11.674861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lists of past events and holidays that need to be referred to when finding CBl days\n",
    "\n",
    "past_activations = ['2022-06-29', '2023-02-28', '2023-05-25', '2023-06-29', '2023-07-27', \n",
    "                    '2023-09-06', '2023-09-07', '2024-01-17','2024-04-17'] \n",
    "\n",
    "daybefore_activations = [(datetime.strptime(date, '%Y-%m-%d') - timedelta(days=1)).strftime('%Y-%m-%d') for date in past_activations]\n",
    "\n",
    "NYISO_holidays = ['2024-01-01', '2024-01-15', '2024-02-19', '2024-05-27' ]\n",
    "\n",
    "past_activations = pd.to_datetime(past_activations, errors='coerce')\n",
    "daybefore_activations = pd.to_datetime(daybefore_activations, errors='coerce')\n",
    "NYISO_holidays = pd.to_datetime(NYISO_holidays, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T13:49:11.683172Z",
     "iopub.status.busy": "2024-06-11T13:49:11.682894Z",
     "iopub.status.idle": "2024-06-11T13:49:13.737976Z",
     "shell.execute_reply": "2024-06-11T13:49:13.737339Z",
     "shell.execute_reply.started": "2024-06-11T13:49:11.683154Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_30days(site_id, event_day):\n",
    "    session = boto3.Session()\n",
    "    s3_client = session.client('s3')\n",
    "    bucket_name = 'rtac-ddr'\n",
    "\n",
    "    sub_folder_prefix = f'processed/{site_id}/1s/daily/'\n",
    "\n",
    "    try:\n",
    "        # Convert event_day to datetime object\n",
    "        event_day_date = datetime.strptime(event_day, '%Y-%m-%d')\n",
    "        start_date = event_day_date - timedelta(days=30)\n",
    "\n",
    "        # List objects in the specified sub-folder\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=sub_folder_prefix)\n",
    "\n",
    "        data_frames = []\n",
    "\n",
    "        if 'Contents' in response:\n",
    "            for obj in response['Contents']:\n",
    "                # Extract the file name from the full key path\n",
    "                file_name = obj['Key'].split('/')[-1]\n",
    "\n",
    "                # Extract the date from the filename (assuming format: US-NY-010523-1900-YYYYMMDD-YYYYMMDD-Aggregated.csv)\n",
    "                parts = file_name.split('-')\n",
    "                if len(parts) >= 5:\n",
    "                    file_date_str = parts[4]\n",
    "                    try:\n",
    "                        file_date = datetime.strptime(file_date_str, '%Y%m%d')\n",
    "                        if start_date <= file_date <= event_day_date:\n",
    "                            file_obj = s3_client.get_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "                            file_content = file_obj['Body'].read()\n",
    "                            data_frame = pd.read_csv(io.BytesIO(file_content))\n",
    "                            data_frames.append(data_frame)\n",
    "                    except ValueError:\n",
    "                        print(f\"Skipping file with invalid date format: {obj['Key']}\")\n",
    "        else:\n",
    "            print(f\"The sub-folder {sub_folder_prefix} in bucket {bucket_name} is empty.\")\n",
    "\n",
    "        # Aggregate all data frames into a single data frame\n",
    "        if data_frames:\n",
    "            combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "            combined_df['generateTime'] = pd.to_datetime(combined_df['generateTime'])\n",
    "            combined_df.set_index('generateTime', inplace=True)\n",
    "\n",
    "            hourly_aggregations = {\n",
    "    \n",
    "                'OPR_DT': 'first',\n",
    "                'OPR_HR':'first',\n",
    "                'Net Load': 'mean',\n",
    "                'ESS Output': 'mean',\n",
    "                'Gross Load': 'mean',\n",
    "                'SoC': 'last',\n",
    "                'SoH': 'last'\n",
    "            }\n",
    "            thirtyday_hourly = combined_df.resample('h').agg(hourly_aggregations)\n",
    "            return thirtyday_hourly\n",
    "        else:\n",
    "            print(\"No files found in the specified date range.\")\n",
    "            return pd.DataFrame()\n",
    "    except s3_client.exceptions.NoSuchBucket:\n",
    "        print(f\"The bucket {bucket_name} does not exist.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "# Example usage:\n",
    "# df = get_30days('site123', '2023-05-25')\n",
    "    \n",
    "patu = get_30days('US-NY-010604-2000', '2024-05-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T17:09:25.307590Z",
     "iopub.status.busy": "2024-06-11T17:09:25.307141Z",
     "iopub.status.idle": "2024-06-11T17:09:25.315405Z",
     "shell.execute_reply": "2024-06-11T17:09:25.314910Z",
     "shell.execute_reply.started": "2024-06-11T17:09:25.307570Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cbl_basis_calculator(thirtydays_df, event_day, event_start_hour, event_end_hour):\n",
    "    event_day = pd.to_datetime(event_day)\n",
    "    # Create an empty dataframe in which to store the CBL values \n",
    "    ten_eligible_days = []\n",
    "    \n",
    "    # get initial seed value for average event period usage level, the one hour with the highest demand (highest net load)\n",
    "    initial_seed_value = thirtydays_df.loc[(thirtydays_df['OPR_HR'] >= event_start_hour) & (thirtydays_df['OPR_HR'] <= event_end_hour), 'Net Load'].max()\n",
    "    event_period_usage_level = initial_seed_value\n",
    "    # Begin with weekday that is 2 days prior to the event. If it is a holiday, an event day, a day before an event day, or a weekend, remove it from the dataset\n",
    "    reversed_thirtydays = thirtydays_df.iloc[::-1]\n",
    "    reversed_thirtydays['OPR_DT'] = pd.to_datetime(reversed_thirtydays['OPR_DT'], errors='coerce')\n",
    "    reversed_thirtydays['is_weekend'] = reversed_thirtydays['OPR_DT'].apply(lambda x: x.weekday() > 4)\n",
    "    \n",
    "         # don't include any past events\n",
    "         # skip the day before the current event\n",
    "         # skip days right before an event\n",
    "         # skip holidays\n",
    "         # skip weekends\n",
    "    mask = reversed_thirtydays['OPR_DT'].isin(past_activations) | \\\n",
    "           (reversed_thirtydays['OPR_DT'] == (event_day - timedelta(days=1))) | \\\n",
    "           reversed_thirtydays['OPR_DT'].isin(daybefore_activations)| \\\n",
    "           reversed_thirtydays['OPR_DT'].isin(NYISO_holidays)| \\\n",
    "           reversed_thirtydays['is_weekend']\n",
    "    \n",
    "    #only look at the event hours for CBL numbers\n",
    "    mask2 = ~reversed_thirtydays['OPR_HR'].between(event_start_hour, event_end_hour)\n",
    "    \n",
    "    #print(f\"Mask:\\n{mask.head(48)}\")\n",
    "    #print(reversed_thirtydays[~mask])\n",
    "\n",
    "    filtered_df = reversed_thirtydays[~mask]\n",
    "    filtered_df = filtered_df.loc[~mask2]\n",
    "    groupedby_day = filtered_df.groupby('OPR_DT').mean().sort_index(ascending=False)\n",
    "    \n",
    "    daily_usage_levels = []\n",
    "    total_sum = sum(daily_usage_levels)\n",
    "    count = 0\n",
    "\n",
    "    #Iterate over the filtered DataFrame\n",
    "    for row in groupedby_day.iterrows():\n",
    "        # Calculate net load average for event period \n",
    "        dailyevent_avg = row[1]['Net Load'].sum()\n",
    "        #eliminate low usage days (less than 25% of seed value or event period usage level)\n",
    "        if dailyevent_avg < (event_period_usage_level*0.25):\n",
    "            continue\n",
    "        # replace the initial seed value if it is the first day\n",
    "        if event_period_usage_level == initial_seed_value:\n",
    "            event_period_usage_level = dailyevent_avg\n",
    "            daily_usage_levels.append(event_period_usage_level)\n",
    "            count += 1\n",
    "        # for the following days, add them to the average calculation for average event period usage level\n",
    "        else:\n",
    "            daily_usage_levels.append(dailyevent_avg)\n",
    "            count += 1\n",
    "        # also add them to the CBL window dataframe\n",
    "        ten_eligible_days.append(row[1])\n",
    "        \n",
    "        if count == 10:\n",
    "            break\n",
    "       #elif count < 10:\n",
    "            #eliminate seed value and low usage step\n",
    "    pf = pd.DataFrame(ten_eligible_days)\n",
    "    top_5 = pf.nlargest(5, 'Net Load')\n",
    "    filtered_top5 = filtered_df.loc[filtered_df.index.normalize().isin(top_5.index)]\n",
    "    CBL_basis = filtered_top5.groupby(['OPR_HR']).agg({'Net Load': 'mean'})\n",
    "    return CBL_basis\n",
    "    # Take the 5 days with the highest average daily event period usage, then for each hour of the event, take the average usage in those top 5 days. This is the CBL basis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T17:09:27.406294Z",
     "iopub.status.busy": "2024-06-11T17:09:27.405615Z",
     "iopub.status.idle": "2024-06-11T17:09:27.421492Z",
     "shell.execute_reply": "2024-06-11T17:09:27.421024Z",
     "shell.execute_reply.started": "2024-06-11T17:09:27.406272Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net Load</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPR_HR</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>348.981097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>340.157619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>344.943614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>345.401002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>331.878649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Net Load\n",
       "OPR_HR            \n",
       "13      348.981097\n",
       "14      340.157619\n",
       "15      344.943614\n",
       "16      345.401002\n",
       "17      331.878649"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbl_basis_calculator(patu,'2024-05-25',13,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-11T13:49:14.012013Z",
     "iopub.status.idle": "2024-06-11T13:49:14.012215Z",
     "shell.execute_reply": "2024-06-11T13:49:14.012123Z",
     "shell.execute_reply.started": "2024-06-11T13:49:14.012113Z"
    }
   },
   "outputs": [],
   "source": [
    "# one for weekday, one for weekend\n",
    "\n",
    "# Inputs:\n",
    "# site, event day, event start time (hour ending), event end time (hour ending)\n",
    "\n",
    "# Dataframes:\n",
    "# DF 1: 30 days data from event and before - hourly\n",
    "# DF 2: CBL basis table - 5 days with highest average daily event period usages, for the hours of the event\n",
    "# DF 3: CBL values: average of each hour of DF 2\n",
    "# DF 4: adjustment hours values\n",
    "# DF 5: adjusted CBLs table\n",
    "\n",
    "# Steps:\n",
    " # access s3 to build DF 1\n",
    " # Input DF 1 into function that builds DF 2 & DF 3\n",
    " # Input DF 1 into function that builds DF 4\n",
    " # Input DF 3 & DF 4 into function to return DF 5\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekday CBL\n",
    "\n",
    "1. connect to s3 bucket\n",
    "2. Calculate CBL basis\n",
    "    a) event period load over last 30 days = cbl window\n",
    "    b) iterate backwards to find the 10 eligible weekdays for basis calculation\n",
    "    c) Take 5 days out of 10 with highest average usage for event period\n",
    "    d) Average usage for each hour from those 5 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekend CBL\n",
    "\n",
    "1. connect to s3 bucket\n",
    "2. 3 most recent weekend days = cbl window\n",
    "3. 2 highest days, average for each hour of event period = cbl basis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjustment Factor\n",
    "\n",
    "1. adjustment period is 2 hour preiod beginning 4 hours prior to start of event\n",
    "2. Apply average day CBL process to adjusment window\n",
    "3. divide by average CBL = adjustment factor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Kubernetes)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
